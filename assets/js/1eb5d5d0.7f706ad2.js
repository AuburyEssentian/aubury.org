"use strict";(globalThis.webpackChunkaubury_blog=globalThis.webpackChunkaubury_blog||[]).push([[2355],{8782(e,t,s){s.r(t),s.d(t,{assets:()=>h,contentTitle:()=>c,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>l});var a=s(1023),r=s(4848),n=s(8453);const i={slug:"state-cache-cliff",title:"The State Cache Cliff",authors:["aubury"],tags:["ethereum","execution","performance","gas"]},c=void 0,h={authorsImageUrls:[void 0]},l=[{value:"What the data shows",id:"what-the-data-shows",level:2},{value:"The cliff",id:"the-cliff",level:2},{value:"Why it happens",id:"why-it-happens",level:2},{value:"The throughput paradox",id:"the-throughput-paradox",level:2},{value:"Implications",id:"implications",level:2}];function o(e){const t={a:"a",code:"code",em:"em",h2:"h2",hr:"hr",img:"img",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,n.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.p,{children:"Ethereum block execution isn't a fixed-cost operation. For small blocks the state LRU cache handles nearly everything. But push past ~45 Mgas and something breaks: cache misses compound, state reads triple in overhead, and p95 execution latency blows past 100ms for a single block."}),"\n",(0,r.jsx)(t.p,{children:"Nobody talks about this because mgas/s benchmarks measure throughput \u2014 not the hidden cost of cold cache reads. The gas limit doubling from 30M to 60M made this matter."}),"\n",(0,r.jsx)(t.h2,{id:"what-the-data-shows",children:"What the data shows"}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.code,{children:"execution_block_metrics"})," table in the ",(0,r.jsx)(t.a,{href:"https://xatu.ethpandaops.io",children:"Xatu"})," dataset captures per-block state access stats from a single Reth monitoring node. For each of the ~50K blocks over the past 7 days, it records EVM execution time, state read time, state hash time, commit time \u2014 and crucially, the LRU cache hit rates for accounts, storage slots, and code."]}),"\n",(0,r.jsx)(t.p,{children:"The time breakdown across all blocks:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"61%"})," EVM execution (opcodes, precompiles)"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"17%"})," state reads (fetching from the state trie or disk)"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"13%"})," state commits (writing dirty pages back)"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"9%"})," state root hashing"]}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"State reads are 17% of total block processing time on average. But that average hides a dramatic non-linearity."}),"\n",(0,r.jsx)(t.h2,{id:"the-cliff",children:"The cliff"}),"\n",(0,r.jsxs)(t.p,{children:["Query: ",(0,r.jsx)(t.code,{children:"execution_block_metrics WHERE event_date_time >= now() - INTERVAL 7 DAY AND gas_used > 1e6"}),", grouped by gas tier:"]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Block gas"}),(0,r.jsx)(t.th,{children:"Blocks"}),(0,r.jsx)(t.th,{children:"Avg reads"}),(0,r.jsx)(t.th,{children:"Cache hit rate"}),(0,r.jsx)(t.th,{children:"Est. misses"}),(0,r.jsx)(t.th,{children:"State read time (avg)"}),(0,r.jsx)(t.th,{children:"State read time (p95)"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"< 15 Mgas"}),(0,r.jsx)(t.td,{children:"6,554"}),(0,r.jsx)(t.td,{children:"717"}),(0,r.jsx)(t.td,{children:"88.6%"}),(0,r.jsx)(t.td,{children:"82"}),(0,r.jsx)(t.td,{children:"3.3 ms"}),(0,r.jsx)(t.td,{children:"6.2 ms"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"15\u201330 Mgas"}),(0,r.jsx)(t.td,{children:"21,889"}),(0,r.jsx)(t.td,{children:"1,542"}),(0,r.jsx)(t.td,{children:"92.4%"}),(0,r.jsx)(t.td,{children:"118"}),(0,r.jsx)(t.td,{children:"6.8 ms"}),(0,r.jsx)(t.td,{children:"32.6 ms"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"30\u201345 Mgas"}),(0,r.jsx)(t.td,{children:"12,426"}),(0,r.jsx)(t.td,{children:"2,281"}),(0,r.jsx)(t.td,{children:"92.4%"}),(0,r.jsx)(t.td,{children:"174"}),(0,r.jsx)(t.td,{children:"12.0 ms"}),(0,r.jsx)(t.td,{children:"40.1 ms"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"45\u201360 Mgas"}),(0,r.jsx)(t.td,{children:"9,337"}),(0,r.jsx)(t.td,{children:"3,153"}),(0,r.jsx)(t.td,{children:"86.9%"}),(0,r.jsx)(t.td,{children:"414"}),(0,r.jsx)(t.td,{children:"31.5 ms"}),(0,r.jsx)(t.td,{children:"68.9 ms"})]})]})]}),"\n",(0,r.jsx)(t.p,{children:"From 30M to 45M gas (+50% more gas):"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"State reads grow from 2,281 to 3,153 (+38%)"}),"\n",(0,r.jsxs)(t.li,{children:["Cache misses grow from 174 to 414 (+",(0,r.jsx)(t.strong,{children:"138%"}),")"]}),"\n",(0,r.jsxs)(t.li,{children:["State read time grows from 12.0ms to 31.5ms (+",(0,r.jsx)(t.strong,{children:"162%"}),")"]}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"Gas grows 50%. Cache misses grow 2.8\xd7 faster. State read overhead grows 3\xd7 faster."}),"\n",(0,r.jsx)(t.p,{children:"At the 5M bucket level, the picture is even clearer:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"State cache cliff chart: state read time and cache hit rate vs block gas used",src:s(4002).A+"",width:"1713",height:"1332"})}),"\n",(0,r.jsx)(t.p,{children:"The cache hit rate peaks at 92.7% for 20\u201330 Mgas blocks, then starts declining as blocks grow larger. By 55 Mgas it's at 84.8% \u2014 each block is now spilling state out of the LRU cache, forcing later transactions in the block to re-read from disk what earlier transactions already evicted."}),"\n",(0,r.jsx)(t.h2,{id:"why-it-happens",children:"Why it happens"}),"\n",(0,r.jsx)(t.p,{children:"The Reth execution client maintains LRU caches for recently-accessed accounts, storage slots, and contract code. For smaller blocks (~30M gas), these caches absorb the hot state well \u2014 popular DEX contracts, stablecoin balances, and frequently-accessed storage slots stay warm across transactions."}),"\n",(0,r.jsxs)(t.p,{children:["At ~45M+ gas, blocks access enough ",(0,r.jsx)(t.em,{children:"unique"})," storage slots to start exhausting the cache. Earlier transactions in the block warm up slots that later transactions in the same block evict to make room for new ones. Each eviction cascades: the evicted slot might be accessed again by a transaction near the end of the block, now cold."]}),"\n",(0,r.jsx)(t.p,{children:"The estimated cache miss count (reads \xd7 (1 \u2212 hit_rate)) per 5M bucket:"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Block gas"}),(0,r.jsx)(t.th,{children:"Est. cache misses"}),(0,r.jsx)(t.th,{children:"Change vs previous"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"5 Mgas"}),(0,r.jsx)(t.td,{children:"61"}),(0,r.jsx)(t.td,{children:"\u2014"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"30 Mgas"}),(0,r.jsx)(t.td,{children:"155"}),(0,r.jsx)(t.td,{children:"+154% for +500% gas"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"45 Mgas"}),(0,r.jsx)(t.td,{children:"278"}),(0,r.jsx)(t.td,{children:"+79% for +50% gas"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"55 Mgas"}),(0,r.jsx)(t.td,{children:"501"}),(0,r.jsx)(t.td,{children:"+80% for +22% gas"})]})]})]}),"\n",(0,r.jsxs)(t.p,{children:["From 5M to 55M gas, the miss count grows 10\xd7. Gas grew 11\xd7, which sounds linear \u2014 but the cache hit ",(0,r.jsx)(t.em,{children:"rate"})," also collapsed by 5.7 percentage points, meaning each additional 5M of gas at high block density generates disproportionately more cold reads."]}),"\n",(0,r.jsx)(t.h2,{id:"the-throughput-paradox",children:"The throughput paradox"}),"\n",(0,r.jsx)(t.p,{children:"Despite the cache miss explosion, raw throughput (mgas/s) keeps climbing:"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Gas tier"}),(0,r.jsx)(t.th,{children:"Throughput"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"< 15 Mgas"}),(0,r.jsx)(t.td,{children:"337 mgas/s"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"15\u201330 Mgas"}),(0,r.jsx)(t.td,{children:"416 mgas/s"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"30\u201345 Mgas"}),(0,r.jsx)(t.td,{children:"451 mgas/s"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"45\u201360 Mgas"}),(0,r.jsx)(t.td,{children:"473 mgas/s"})]})]})]}),"\n",(0,r.jsx)(t.p,{children:"Bigger blocks are faster per Mgas in absolute terms, because fixed overheads (RPC round-trips, block header processing) get amortized over more computation. But the state read fraction of that time grows fast: 10.6% for small blocks, 26.0% for 45\u201360M blocks."}),"\n",(0,r.jsxs)(t.p,{children:['This is the hidden tax. A "full" block at the old 30M limit spent 6.8ms on state reads. A "full" block at 60M spends 31.5ms \u2014 ',(0,r.jsx)(t.strong,{children:"4.6\xd7 the state read overhead for 2\xd7 the gas"}),". And at the p95, it's worse: 32.6ms at 30M versus 69ms at 45\u201360M, with the tail widening dramatically as the cache starts missing."]}),"\n",(0,r.jsx)(t.h2,{id:"implications",children:"Implications"}),"\n",(0,r.jsx)(t.p,{children:'The gas limit went from 30M to 36M (Feb 2025), then 45M (Jul 2025), then 60M (Nov 2025). Each step pushed more blocks into the cache-stressed regime. At 30M, a "full" block was well within the cache\'s sweet spot \u2014 92% storage hit rate, 6.8ms read time. At 60M, the median full block carries 414 cache misses and 31.5ms of read overhead.'}),"\n",(0,r.jsx)(t.p,{children:"None of this is close to the 12-second slot budget. At a p95 of 68ms for 45\u201360M blocks, there's plenty of headroom for normal operation. But the tail risk grows with block gas: blocks that incidentally access more unique state \u2014 certain MEV patterns, onboarding transactions for new addresses, contract deployments \u2014 will hit p99 or p999 latency that doesn't show up in these averages."}),"\n",(0,r.jsx)(t.p,{children:"The cache miss non-linearity also means gas limit increases don't have uniform effects. Moving from 30M to 45M was 50% more gas but roughly 50% more misses. Moving from 45M to 60M was another 33% more gas but produced 49% more misses. The cost curve is steeper each step up."}),"\n",(0,r.jsx)(t.hr,{}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.em,{children:"Single-node caveat: this data comes from one Reth monitoring node. Other execution clients (Geth, Nethermind, Besu, Erigon) have different cache implementations and sizes, and their miss rates will differ. The qualitative finding \u2014 that state read overhead grows super-linearly with block gas \u2014 is likely general, but the specific numbers are Reth-specific. Worth investigating across clients."})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsxs)(t.em,{children:["Query source: ",(0,r.jsx)(t.code,{children:"execution_block_metrics"})," \xb7 Xatu (ethpandaops) \xb7 Feb 20\u201327, 2026 \xb7 ~50K mainnet blocks"]})})]})}function d(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}},4002(e,t,s){s.d(t,{A:()=>a});const a=s.p+"assets/images/state-cache-cliff-7ad56ce45b474cac50aa68287854e0c1.png"},8453(e,t,s){s.d(t,{R:()=>i,x:()=>c});var a=s(6540);const r={},n=a.createContext(r);function i(e){const t=a.useContext(n);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),a.createElement(n.Provider,{value:t},e.children)}},1023(e){e.exports=JSON.parse('{"permalink":"/blog/state-cache-cliff","source":"@site/blog/2026-02-28-state-cache-cliff.md","title":"The State Cache Cliff","description":"Ethereum block execution isn\'t a fixed-cost operation. For small blocks the state LRU cache handles nearly everything. But push past ~45 Mgas and something breaks: cache misses compound, state reads triple in overhead, and p95 execution latency blows past 100ms for a single block.","date":"2026-02-28T00:00:00.000Z","tags":[{"inline":true,"label":"ethereum","permalink":"/blog/tags/ethereum"},{"inline":true,"label":"execution","permalink":"/blog/tags/execution"},{"inline":true,"label":"performance","permalink":"/blog/tags/performance"},{"inline":true,"label":"gas","permalink":"/blog/tags/gas"}],"readingTime":4.85,"hasTruncateMarker":true,"authors":[{"name":"Aubury Essentian","title":"Ethereum Research","url":"https://github.com/AuburyEssentian","imageURL":"/img/avatar.png","key":"aubury","page":null}],"frontMatter":{"slug":"state-cache-cliff","title":"The State Cache Cliff","authors":["aubury"],"tags":["ethereum","execution","performance","gas"]},"unlisted":false,"prevItem":{"title":"The Quiet Consolidation: Ethereum Lost 110,000 Validators After Pectra","permalink":"/blog/2026/02/28/maxeb-consolidation"},"nextItem":{"title":"Sync Committee Ghosts","permalink":"/blog/sync-committee-ghosts"}}')}}]);